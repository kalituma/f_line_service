try:
    import ray  # type: ignore
except ImportError:
    ray = None  # type: ignore

import os
from datetime import datetime
from typing import Dict, Any, List, Callable, Optional

from sv import DEFAULT_JOB_QUEUE_DB
from sv.task.task_base import TaskBase
from sv.utils.logger import setup_logger
from sv.daemon.server_state import ServerAnalysisStatus
from sv.daemon.module.http_request_client import HttpRequestError
from sv.daemon.module.update_handler import send_video_status_update
from sv.daemon.daemon_state import STATUS_SUCCESS, STATUS_FAILED, STATUS_NOT_EXISTS
from sv.daemon.module.fault_injector import FaultInjector


@ray.remote
class FlineTaskSplitExecutor:
    """Ray Actorë¡œ ìˆœì°¨ ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” í´ë˜ìŠ¤ (ë°ì´í„° ë¶„í•  ì§€ì›)"""

    def __init__(self, executor_id: int, base_work_dir: str, update_url: str, 
                 fault_injector: Optional[FaultInjector] = None):
        self.executor_id = executor_id
        self.base_work_dir = base_work_dir
        self.update_url = update_url
        self.logger = setup_logger(f"Executor-{executor_id}")
        self._job_queue_service = None  # Lazy initialization
        self.fault_injector = fault_injector  # Optional fault injection

    @property
    def job_queue_service(self):
        """í•„ìš”í•  ë•Œë§Œ ì„œë¹„ìŠ¤ ìƒì„± (ê° Ray actor í”„ë¡œì„¸ìŠ¤ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ)"""
        if self._job_queue_service is None:
            from sv.backend.service.job_queue_service import JobQueueService

            self._job_queue_service = JobQueueService(DEFAULT_JOB_QUEUE_DB)
            self.logger.info(f"âœ“ JobQueueService initialized in Ray actor with db_path={DEFAULT_JOB_QUEUE_DB}")

        return self._job_queue_service
    
    def _inject_fault(self, method_name: str, context: Optional[Dict[str, Any]] = None) -> None:
        """
        Fault injection ì²´í¬ (fault_injectorê°€ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ)
        
        Args:
            method_name: í˜„ì¬ ë©”ì„œë“œ ì´ë¦„
            context: ë©”ì„œë“œ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
        """
        if self.fault_injector:
            self.fault_injector.inject(method_name, context)

    def execute_sequential_tasks(
            self,
            tasks: List[TaskBase],
            loop_context: Dict[str, Any],
            data_processor: Optional[Callable[[Dict[str, Any]], Any]] = None
    ) -> Dict[str, Any]:
        """
        ìˆœì°¨ì ìœ¼ë¡œ ì—¬ëŸ¬ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            tasks: ì‹¤í–‰í•  ì‘ì—… ëª©ë¡ (TaskBase ì¸ìŠ¤í„´ìŠ¤)
            loop_context: ë£¨í”„ì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            data_processor: ì²« ë²ˆì§¸ Task ê²°ê³¼ë¥¼ ì²˜ë¦¬í•  í•¨ìˆ˜ (ë°ì´í„° ë¶„í•  ë“±)
            
        Returns:
            ì „ì²´ ì‹¤í–‰ ê²°ê³¼
            
        Example:
            ```python
            def split_data(result):
                # Task 1ì˜ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ë¼ë©´ ê°œë³„ ì•„ì´í…œ ë°˜í™˜
                return result.get('items', [])
            
            result = executor.execute_sequential_tasks(
                tasks=[task1, task2, task3],
                loop_context={'job_id': 123},
                data_processor=split_data
            )
            ```
        """
        self.logger.info(f"Executor {self.executor_id} executing {len(tasks)} sequential tasks")
        self.logger.info(f"Loop context: {loop_context}")

        results = {
            'executor_id': self.executor_id,
            'loop_context': loop_context,
            'tasks': [],
            'status': STATUS_SUCCESS.to_str(),
            'completed_at': datetime.now().isoformat(),
            'total_duration': 0,
            'error_count': 0,
            'error': None  # ìµœìƒë‹¨ ì—ëŸ¬ ë©”ì‹œì§€
        }

        start_time = datetime.now()
        task_context = {}  # ì‘ì—…ë“¤ ê°„ ì»¨í…ìŠ¤íŠ¸ ê³µìœ 

        for idx, task in enumerate(tasks, 1):
            try:
                self.logger.info(f"[{idx}/{len(tasks)}] Executing task: {task.task_name}")

                task_start = datetime.now()
                task_result = task.execute(task_context)
                task_duration = (datetime.now() - task_start).total_seconds()

                # ì‘ì—… ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                task_context[task.task_name] = task_result

                self.logger.info(
                    f"[{idx}/{len(tasks)}] Task '{task.task_name}' completed "
                    f"({task_duration:.2f}s)"
                )

                results['tasks'].append({
                    'task_name': task.task_name,
                    'status': STATUS_SUCCESS.to_str(),
                    'result': task_result,
                    'duration': task_duration
                })

            except Exception as e:
                error_msg = f"Task '{task.task_name}' failed: {str(e)}"
                self.logger.error(error_msg, exc_info=True)

                # í‘œì¤€ ì—ëŸ¬ ì„¤ì • (ìµœìƒë‹¨ì— ì²« ë²ˆì§¸ ì—ëŸ¬ë§Œ ê¸°ë¡)
                if not results.get('error'):
                    results['error'] = error_msg
                results['status'] = STATUS_FAILED.to_str()
                results['error_count'] += 1
                
                results['tasks'].append({
                    'task_name': task.task_name,
                    'status': STATUS_FAILED.to_str(),
                    'error': str(e)
                })

                # ì—ëŸ¬ ë°œìƒ ì‹œ ë‹¤ìŒ ì‘ì—…ì€ ê³„ì† ì‹¤í–‰í• ì§€ ì„ íƒ
                # ì—¬ê¸°ì„œëŠ” ê³„ì† ì‹¤í–‰í•˜ë„ë¡ ì„¤ì • (í•„ìš”ì‹œ breakë¡œ ì¤‘ë‹¨)
                continue

        total_duration = (datetime.now() - start_time).total_seconds()
        results['total_duration'] = total_duration
        results['task_context'] = task_context

        self.logger.info(
            f"Sequential task execution completed "
            f"(Status: {results['status']}, Total: {total_duration:.2f}s, Errors: {results['error_count']})"
        )

        return results

    def _create_work_directory(self, loop_context: Dict[str, Any]) -> tuple:
        """
        Job ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        
        Returns:
            (job_work_dir, error_result) - ì„±ê³µì‹œ (path, None), ì‹¤íŒ¨ì‹œ (None, error_dict)
        """
        # Fault injection ì²´í¬
        self._inject_fault("_create_work_directory", loop_context)
        
        work_id = loop_context.get('work_id')
        frfr_id = loop_context.get('frfr_id')
        analysis_id = loop_context.get('analysis_id')

        work_folder_name = f"{work_id}_{frfr_id}_{analysis_id}"
        job_work_dir = os.path.join(self.base_work_dir, work_folder_name)

        try:
            os.makedirs(job_work_dir, exist_ok=True)
            self.logger.info(f"âœ“ Job work directory created: {job_work_dir}")
            return job_work_dir, None
        except Exception as e:
            error_msg = f"Failed to create job work directory: {str(e)}"
            self.logger.error(f"âŒ {error_msg}", exc_info=True)
            error_result = self._create_error_result(loop_context, error_msg)
            return None, error_result

    def _initialize_results(self, loop_context: Dict[str, Any], job_work_dir: str) -> Dict[str, Any]:
        """ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”"""
        return {
            'executor_id': self.executor_id,
            'loop_context': loop_context,
            'job_work_dir': job_work_dir,
            'primary_task': None,
            'item_results': [],
            'status': STATUS_SUCCESS.to_str(),
            'completed_at': datetime.now().isoformat(),
            'total_duration': 0,
            'error_count': 0,
            'error': None  # ìµœìƒë‹¨ ì—ëŸ¬ ë©”ì‹œì§€ (on_job_completeì—ì„œ ì‚¬ìš©)
        }
    
    def _create_error_result(self, loop_context: Dict[str, Any], error_msg: str, 
                            job_work_dir: str = None, duration: float = 0) -> Dict[str, Any]:
        """
        ì—ëŸ¬ ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ìƒì„±
        
        Args:
            loop_context: ë£¨í”„ ì»¨í…ìŠ¤íŠ¸
            error_msg: ì—ëŸ¬ ë©”ì‹œì§€
            job_work_dir: ì‘ì—… ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ None)
            duration: ì‹¤í–‰ ì‹œê°„
            
        Returns:
            í‘œì¤€í™”ëœ ì—ëŸ¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return {
            'executor_id': self.executor_id,
            'loop_context': loop_context,
            'job_work_dir': job_work_dir,
            'status': STATUS_FAILED.to_str(),
            'error': error_msg,  # ìµœìƒë‹¨ì— ì—ëŸ¬ ë©”ì‹œì§€ (on_job_completeê°€ ì½ìŒ)
            'completed_at': datetime.now().isoformat(),
            'total_duration': duration,
            'error_count': 1
        }
    
    def _set_error_on_results(self, results: Dict[str, Any], error_msg: str) -> None:
        """
        ê¸°ì¡´ resultsì— ì—ëŸ¬ ì •ë³´ë¥¼ ì„¤ì • (ìƒíƒœ ë³€ê²½)
        
        Args:
            results: ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            error_msg: ì—ëŸ¬ ë©”ì‹œì§€
        """
        results['status'] = STATUS_FAILED.to_str()
        results['error'] = error_msg  # ìµœìƒë‹¨ì— ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì •
        results['error_count'] += 1

    def _execute_primary_task(self, primary_task: TaskBase, task_context: Dict[str, Any],
                              results: Dict[str, Any]) -> tuple:
        """
        Primary task ì‹¤í–‰
        
        Returns:
            (primary_result, is_success)
        """
        # Fault injection ì²´í¬

        try:
            self.logger.info(f"[1] Executing primary task: {primary_task.task_name}")
            self._inject_fault("_execute_primary_task", task_context)

            primary_start = datetime.now()
            primary_result = primary_task.execute(task_context)
            primary_duration = (datetime.now() - primary_start).total_seconds()

            task_context[primary_task.task_name] = primary_result

            self.logger.info(
                f"[1] Primary task '{primary_task.task_name}' completed ({primary_duration:.2f}s)"
            )

            results['primary_task'] = {
                'task_name': primary_task.task_name,
                'status': STATUS_SUCCESS.to_str(),
                'result': primary_result,
                'duration': primary_duration
            }

            return primary_result, True

        except Exception as e:
            error_msg = f"Primary task '{primary_task.task_name}' failed: {str(e)}"
            self.logger.error(error_msg, exc_info=True)

            # í‘œì¤€ ì—ëŸ¬ ì„¤ì • (ìµœìƒë‹¨ì— error ì¶”ê°€)
            self._set_error_on_results(results, error_msg)
            results['primary_task'] = {
                'task_name': primary_task.task_name,
                'status': STATUS_FAILED.to_str(),
                'error': str(e)
            }

            return None, False

    def _split_data(self, primary_result: Any, data_splitter: Callable,
                    results: Dict[str, Any]) -> tuple:
        """
        ë°ì´í„° ë¶„í• 
        
        Returns:
            (data_items, is_success)
        """
        # Fault injection ì²´í¬

        try:
            self.logger.info("[2] Splitting data from primary task result")
            self._inject_fault("_split_data", {'primary_result': primary_result})

            data_items = data_splitter(primary_result)

            if not isinstance(data_items, list):
                data_items = [data_items]

            self.logger.info(f"[2] Data split into {len(data_items)} items")

            return data_items, True

        except Exception as e:
            error_msg = f"Data splitting failed: {str(e)}"
            self.logger.error(error_msg, exc_info=True)

            # í‘œì¤€ ì—ëŸ¬ ì„¤ì •
            self._set_error_on_results(results, error_msg)

            return None, False

    def _execute_secondary_tasks(self, secondary_tasks: List[TaskBase], item_context: Dict[str, Any],
                                 data_idx: int, total_items: int,
                                 continue_on_error: bool) -> tuple:
        """
        Secondary tasks ì‹¤í–‰
        
        Returns:
            (item_result, should_break)
        """
        # Fault injection ì²´í¬
        # self._inject_fault("_execute_secondary_tasks", {
        #     'data_idx': data_idx,
        #     'total_items': total_items,
        #     **item_context
        # })
        
        item_result = {
            'tasks': [],
            'status': STATUS_SUCCESS.to_str()
        }
        should_break = False

        for task_seq, task in enumerate(secondary_tasks, 1):
            try:
                self.logger.info(
                    f"[3.{data_idx}/{total_items}.{task_seq}/{len(secondary_tasks)}] "
                    f"Executing task: {task.task_name}"
                )

                task_start = datetime.now()
                task_result = task.execute(item_context)
                task_duration = (datetime.now() - task_start).total_seconds()

                item_context[task.task_name] = task_result

                self.logger.info(
                    f"[3.{data_idx}/{total_items}.{task_seq}/{len(secondary_tasks)}] "
                    f"Task '{task.task_name}' completed ({task_duration:.2f}s)"
                )

                item_result['tasks'].append({
                    'task_name': task.task_name,
                    'status': STATUS_SUCCESS.to_str(),
                    'result': task_result,
                    'duration': task_duration
                })

            except Exception as e:
                error_msg = f"Task '{task.task_name}' failed: {str(e)}"
                self.logger.error(error_msg, exc_info=True)

                item_result['status'] = STATUS_FAILED.to_str()
                item_result['tasks'].append({
                    'task_name': task.task_name,
                    'status': STATUS_FAILED.to_str(),
                    'error': str(e)
                })

                if not continue_on_error:
                    should_break = True
                    break

        return item_result, should_break

    def _update_job_status(self, job_id: Optional[int], status_str: str, data_idx: int, total_items: int) -> None:
        """
        Job ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            job_id: ì—…ë°ì´íŠ¸í•  jobì˜ ID
            status_str: ë³€ê²½í•  ìƒíƒœ ('success', 'failed', 'not_exists' ë“±)
            data_idx: í˜„ì¬ ë°ì´í„° ì¸ë±ìŠ¤ (ë¡œê¹…ìš©)
            total_items: ì „ì²´ ë°ì´í„° ê°œìˆ˜ (ë¡œê¹…ìš©)
        """
        if not job_id:
            self.logger.warning(
                f"[3.{data_idx}/{total_items}.update] âŠ˜ Job ID is None (ìŠ¤í‚µ)"
            )
            return
        
        try:
            from sv.backend.work_status import WorkStatus
            
            # status_strì— ë”°ë¼ WorkStatus ë§¤í•‘
            status_map = {
                'success': WorkStatus.COMPLETED,
                'failed': WorkStatus.FAILED,
                'not_exists': WorkStatus.FAILED,  # íŒŒì¼ ì—†ìŒë„ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            }
            
            work_status = status_map.get(status_str, WorkStatus.FAILED)
            status_display = work_status.value.upper()

            self.logger.info(
                f"[3.{data_idx}/{total_items}.update] "
                f"Updating job status to {status_display}: job_id={job_id}"
            )

            self.job_queue_service.update_job_status(
                job_id=job_id,
                status=work_status
            )

            self.logger.info(
                f"[3.{data_idx}/{total_items}.update] "
                f"âœ“ Job status updated to {status_display}: job_id={job_id}"
            )
        except Exception as e:
            self.logger.error(
                f"[3.{data_idx}/{total_items}.update] "
                f"âŒ Failed to update job status: job_id={job_id}, status={status_str}, error={str(e)}",
                exc_info=True
            )

    def _finalize_item_result(self, item_result: Dict[str, Any], item_start: datetime, 
                              results: Dict[str, Any], data_idx: int, total_items: int) -> None:
        """
        ì•„ì´í…œ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì™„ë£Œí•˜ê³  Job ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        - duration ê³„ì‚° ë° ì„¤ì •
        - resultsì— item_result ì¶”ê°€
        - item_result['status']ì— ë”°ë¼ job status ì—…ë°ì´íŠ¸
        
        Args:
            item_result: ì•„ì´í…œ ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            item_start: ì•„ì´í…œ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„
            results: ì „ì²´ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            data_idx: í˜„ì¬ ë°ì´í„° ì¸ë±ìŠ¤
            total_items: ì „ì²´ ë°ì´í„° ê°œìˆ˜
        """
        # Duration ê³„ì‚° ë° ì„¤ì •
        item_result['duration'] = (datetime.now() - item_start).total_seconds()
        
        # ê²°ê³¼ì— ì¶”ê°€
        results['item_results'].append(item_result)
        
        # Job ìƒíƒœ ì—…ë°ì´íŠ¸ (item_result['status']ì— ë”°ë¼)
        if item_result['status'] == STATUS_SUCCESS.to_str():
            status_str = 'success'
        elif item_result['status'] == STATUS_NOT_EXISTS.to_str():
            status_str = 'not_exists'
        else:  # STATUS_FAILED
            status_str = 'failed'
        
        self._update_job_status(
            job_id=item_result.get('job_id'),
            status_str=status_str,
            data_idx=data_idx,
            total_items=total_items
        )

    def _process_data_items(self, data_items: List[Any], video_dirs: List[Any], secondary_tasks: List[TaskBase],
                            task_context: Dict[str, Any], loop_context: Dict[str, Any],
                            continue_on_error: bool, results: Dict[str, Any]) -> None:
        """ê° ë°ì´í„° ì•„ì´í…œë³„ ì²˜ë¦¬"""
        
        for data_idx, (data_item, vid_dir) in enumerate(zip(data_items, video_dirs), 1):
            self.logger.info(f"[3.{data_idx}/{len(data_items)}] Processing data item: {data_item}")

            item_context = task_context.copy()
            item_context['job_dir'] = vid_dir
            item_context['current_data'] = data_item
            item_context['data_index'] = data_idx - 1
            item_context['total_data_items'] = len(data_items)

            item_result = {
                'data_item': data_item,
                'data_index': data_idx - 1,
                'status': STATUS_SUCCESS.to_str()
            }

            item_start = datetime.now()

            # ==================== Step 3.1: Pre-secondary ì½œë°± ì‹¤í–‰ ====================
            try:
                self.logger.info(
                    f"[3.{data_idx}/{len(data_items)}.pre] Executing pre-secondary callback"
                )
                item_result['job_id'] = self._on_secondary_tasks_start(data_item, vid_dir, loop_context)

                self.logger.info(
                    f"[3.{data_idx}/{len(data_items)}.pre] Pre-secondary callback completed successfully"
                )
            except FileNotFoundError as e:
                item_result['status'] = STATUS_NOT_EXISTS.to_str()
                item_result['error'] = f"File not found: {str(e)}"
                results['error_count'] += 1
                
                # ê²°ê³¼ ì™„ë£Œ ë° Job ìƒíƒœ ì—…ë°ì´íŠ¸
                self._finalize_item_result(item_result, item_start, results, data_idx, len(data_items))
                
                if not continue_on_error:
                    break
                continue
            except Exception as e:
                error_msg = f"Pre-secondary callback failed for data_item {data_idx}: {str(e)}"
                self.logger.error(error_msg, exc_info=True)
                item_result['status'] = STATUS_FAILED.to_str()
                item_result['error'] = error_msg
                results['error_count'] += 1
                
                # ê²°ê³¼ ì™„ë£Œ ë° Job ìƒíƒœ ì—…ë°ì´íŠ¸
                self._finalize_item_result(item_result, item_start, results, data_idx, len(data_items))
                
                if not continue_on_error:
                    break
                continue

            # ==================== Step 3.2: Secondary Tasks ì‹¤í–‰ ====================
            secondary_result, should_break = self._execute_secondary_tasks(
                secondary_tasks, item_context, data_idx, len(data_items), continue_on_error
            )

            item_result['tasks'] = secondary_result['tasks']
            if secondary_result['status'] == 'failed':
                item_result['status'] = 'failed'
                results['error_count'] += 1
                
                if should_break:
                    # ê²°ê³¼ ì™„ë£Œ ë° Job ìƒíƒœ ì—…ë°ì´íŠ¸ (break ì „)
                    self._finalize_item_result(item_result, item_start, results, data_idx, len(data_items))
                    break

            # ==================== Step 3.3: ê²°ê³¼ ì™„ë£Œ ë° Job Status ì—…ë°ì´íŠ¸ ====================
            self._finalize_item_result(item_result, item_start, results, data_idx, len(data_items))

    def execute_with_data_splitting(
            self,
            primary_task: TaskBase,
            secondary_tasks: List[TaskBase],
            loop_context: Dict[str, Any],
            data_splitter: Callable[[Any], List[Any]],
            continue_on_error: bool = True,
    ) -> Dict[str, Any]:
        """
        Task 1ì„ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ë¶„í• í•˜ì—¬ ê° ë°ì´í„°ì— ëŒ€í•´ ìˆœì°¨ Taskë“¤ì„ ì‹¤í–‰
        
        **ì‹¤í–‰ íë¦„:**
        1. Job ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        2. Primary task ì‹¤í–‰
        3. ë°ì´í„° ë¶„í• 
        4. ê° ë°ì´í„° ì•„ì´í…œë³„ ì²˜ë¦¬:
           - Pre-secondary ì½œë°± ì‹¤í–‰
           - Secondary tasks ì‹¤í–‰
        
        Args:
            primary_task: ë¨¼ì € ì‹¤í–‰í•  ì£¼ìš” ì‘ì—… (Task 1)
            secondary_tasks: ë¶„í• ëœ ê° ë°ì´í„°ì— ëŒ€í•´ ì‹¤í–‰í•  ì‘ì—… ë¦¬ìŠ¤íŠ¸
            loop_context: ë£¨í”„ì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            data_splitter: ì£¼ìš” ì‘ì—… ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„í• í•˜ëŠ” í•¨ìˆ˜
            continue_on_error: ì—ëŸ¬ ë°œìƒ ì‹œ ê³„ì† ì‹¤í–‰í• ì§€ ì—¬ë¶€
            
        Returns:
            ì „ì²´ ì‹¤í–‰ ê²°ê³¼
        """

        start_time = datetime.now()

        # ==================== Step 0: ì‘ì—… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± ====================
        work_root_dir, error_result = self._create_work_directory(loop_context)
        if error_result:
            return error_result

        results = self._initialize_results(loop_context, work_root_dir)
        task_context = {
            'work_root_dir': work_root_dir,
            'loop_context': loop_context
        }

        # ==================== Step 1: Primary task ì‹¤í–‰ ====================
        primary_result, is_success = self._execute_primary_task(primary_task, task_context, results)
        if not is_success:
            results['total_duration'] = (datetime.now() - start_time).total_seconds()
            return results

        # ==================== Step 2: ë°ì´í„° ë¶„í•  ====================
        data_items, is_success = self._split_data(primary_result, data_splitter, results)
        if not is_success:
            results['total_duration'] = (datetime.now() - start_time).total_seconds()
            return results

        # ==================== Step 2.5: Videoë³„ í´ë” ìƒì„± ====================
        video_dirs, is_success = self._create_video_directories(data_items, loop_context, work_root_dir, results)
        if not is_success:
            results['total_duration'] = (datetime.now() - start_time).total_seconds()
            return results

        # ==================== Step 3: ê° ë°ì´í„° ì•„ì´í…œë³„ ì²˜ë¦¬ ====================
        self._process_data_items(data_items, video_dirs, secondary_tasks, task_context, loop_context, continue_on_error,
                                 results)

        # ==================== ì™„ë£Œ ====================
        results['total_duration'] = (datetime.now() - start_time).total_seconds()
        
        # ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš° ìµœìƒë‹¨ì— ì¢…í•© ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì •
        if results['error_count'] > 0 and not results.get('error'):
            results['error'] = f"{results['error_count']} item(s) failed during processing"

        self.logger.info(
            f"Data splitting task execution completed "
            f"(Total: {results['total_duration']:.2f}s, Errors: {results['error_count']})"
        )

        return results

    def _create_video_directories(self, data_items: List[Any], loop_context: Dict[str, Any],
                                  work_root_dir: str, results: Dict[str, Any]) -> tuple:
        """
        data_itemsì˜ ê° video_nameê³¼ loop_contextì˜ start_timeì„ '_'ë¡œ ê²°í•©í•˜ì—¬
        work_root_dir í•˜ìœ„ì— videoë³„ í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            data_items: ë¹„ë””ì˜¤ ë°ì´í„° ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
            loop_context: ë£¨í”„ì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (start_time í¬í•¨)
            work_root_dir: ì‘ì—… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            results: ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ì—ëŸ¬ ë°œìƒ ì‹œ ì—…ë°ì´íŠ¸)
            
        Returns:
            (video_directories, is_success) - ì„±ê³µì‹œ (list, True), ì‹¤íŒ¨ì‹œ (None, False)
            
        Example:
            - data_items = ['video1.mp4', 'video2.mp4']
            - loop_context = {'start_time': '2025-10-09T19:52:37'}
            - work_root_dir = '/path/to/work'
            - ìƒì„± í´ë”: /path/to/work/video1.mp4_2025-10-09T19:52:37
                       /path/to/work/video2.mp4_2025-10-09T19:52:37
        """
        try:
            self.logger.info("[2.5] Creating video directories")
            
            # Fault injection ì²´í¬
            self._inject_fault("_create_video_directories", {
                'data_item_count': len(data_items),
                'work_root_dir': work_root_dir,
                **loop_context
            })

            video_directories = []
            start_time = loop_context.get('start_time')

            self.logger.info(f"     work_root_dir: {work_root_dir}")
            self.logger.info(f"     start_time: {start_time}, total items: {len(data_items)}")

            for idx, data_item in enumerate(data_items, 1):
                # data_itemì—ì„œ video_name ì¶”ì¶œ
                video_name = data_item.get('video_name', 'UNKNOWN')

                # video_nameê³¼ start_timeì„ '_'ë¡œ ê²°í•©í•˜ì—¬ í´ë”ëª… ìƒì„±
                video_dir_name = f"{start_time}_{video_name}"
                video_directory = os.path.join(work_root_dir, video_dir_name)
                video_directories.append(video_directory)

                try:
                    os.makedirs(video_directory, exist_ok=True)
                    self.logger.info(f"     [{idx}/{len(data_items)}] âœ“ Video directory created: {video_directory}")
                except Exception as e:
                    error_msg = f"Failed to create video directory '{video_directory}': {str(e)}"
                    self.logger.error(f"     [{idx}/{len(data_items)}] âŒ {error_msg}", exc_info=True)
                    
                    # ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ë¯€ë¡œ ì¦‰ì‹œ ì¤‘ë‹¨
                    self._set_error_on_results(results, error_msg)
                    return None, False

            self.logger.info("[2.5] Video directory creation completed successfully")
            return video_directories, True

        except Exception as e:
            error_msg = f"Video directories creation failed: {str(e)}"
            self.logger.error(f"âŒ {error_msg}", exc_info=True)
            
            # í‘œì¤€ ì—ëŸ¬ ì„¤ì •
            self._set_error_on_results(results, error_msg)
            return None, False

    def _extract_callback_context(self, data_item: Dict[str, Any], loop_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì½œë°± ì‹¤í–‰ì— í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            data_item: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„° ì•„ì´í…œ
            loop_context: Jobì˜ ë£¨í”„ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ì¶”ì¶œëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (work_id, frfr_id, analysis_id, video_name, video_url)
        """
        context = {
            'work_id': loop_context.get('work_id'),
            'frfr_id': loop_context.get('frfr_id'),
            'analysis_id': loop_context.get('analysis_id'),
            'video_name': data_item if isinstance(data_item, str) else data_item.get('video_name', 'unknown'),
            'video_url': data_item.get('video_url') if isinstance(data_item, dict) else ''
        }

        self.logger.info("=" * 80)
        self.logger.info("ğŸ“¤ Pre-secondary callback ì‹¤í–‰")
        self.logger.info(f"   work_id: {context['work_id']}")
        self.logger.info(f"   frfr_id: {context['frfr_id']}, analysis_id: {context['analysis_id']}")
        self.logger.info(f"   video_name: {context['video_name']}")
        self.logger.info(f"   video_url: {context['video_url']}")
        self.logger.info(f"   update_url: {self.update_url}")
        self.logger.info("=" * 80)

        return context

    def _validate_video_file(self, video_url: str) -> tuple[bool, ServerAnalysisStatus]:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ì ì ˆí•œ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            video_url: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            (íŒŒì¼ ì¡´ì¬ ì—¬ë¶€, ë¶„ì„ ìƒíƒœ)
        """
        file_exists = os.path.isfile(video_url)

        if file_exists:
            self.logger.info(f"âœ“ íŒŒì¼ ì¡´ì¬ í™•ì¸: {video_url}")
            status = ServerAnalysisStatus.STAT_002  # ë¶„ì„ ì¤€ë¹„ ì¤‘
        else:
            self.logger.warning(f"âš ï¸  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {video_url}")
            status = ServerAnalysisStatus.STAT_005  # íŒŒì¼ ì—†ìŒ ì—ëŸ¬

        return file_exists, status

    def _register_job_to_queue(self, work_id: int, frfr_id: str, analysis_id: str,
                               video_url: str, workspace: str, file_exists: bool) -> Optional[int]:
        """
        Job Queueì— ì‘ì—…ì„ ë“±ë¡í•©ë‹ˆë‹¤.
        
        Args:
            work_id: Work Queue ID
            frfr_id: ì‚°ë¶ˆ ì •ë³´ ID
            analysis_id: ë¶„ì„ ID
            video_url: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            workspace: ì‘ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ
            file_exists: íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
            
        Returns:
            ë“±ë¡ëœ job_id ë˜ëŠ” None (work_idê°€ ì—†ê±°ë‚˜ ë“±ë¡ ì‹¤íŒ¨ ì‹œ)
            
        Note:
            íŒŒì¼ì´ ì—†ì–´ë„ Jobì„ ë“±ë¡í•˜ì—¬ ì¶”ì  ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
            íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸° ìƒíƒœë¥¼ FAILEDë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        """
        if not work_id:
            self.logger.warning("âš ï¸  work_idê°€ ì—†ì–´ Job Queue ë“±ë¡ ê±´ë„ˆëœ€")
            return None

        if not file_exists:
            self.logger.warning("âš ï¸  íŒŒì¼ì´ ì—†ì–´ Job Queue ë“±ë¡ ê±´ë„ˆëœ€")
            return None

        try:
            from sv.backend.work_status import WorkStatus

            job_id = self.job_queue_service.add_job(
                work_id=work_id,
                frfr_id=frfr_id,
                analysis_id=analysis_id,
                video_url=video_url,
                workspace=workspace,
                status=WorkStatus.PENDING
            )

            if job_id:
                self.logger.info(f"âœ“ Job Queueì— ë“±ë¡ ì™„ë£Œ: job_id={job_id}, workspace={workspace}")
            else:
                self.logger.warning(f"âš ï¸  Job Queue ë“±ë¡ ì‹¤íŒ¨ (ì¤‘ë³µ ê°€ëŠ¥): work_id={work_id}")

            return job_id

        except Exception as e:
            self.logger.error(f"âŒ Job Queue ë“±ë¡ ì¤‘ ì—ëŸ¬: {str(e)}", exc_info=True)
            # Job Queue ë“±ë¡ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ None ë°˜í™˜
            return None

    def _send_video_status(self, frfr_id: str, analysis_id: str,
                           video_name: str, analysis_status: ServerAnalysisStatus) -> None:
        """
        ì™¸ë¶€ ì„œë²„ì— ë¹„ë””ì˜¤ ìƒíƒœë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            frfr_id: ì‚°ë¶ˆ ì •ë³´ ID
            analysis_id: ë¶„ì„ ID
            video_name: ë¹„ë””ì˜¤ ì´ë¦„
            analysis_status: ë¶„ì„ ìƒíƒœ
            
        Raises:
            HttpRequestError: ìƒíƒœ ì „ì†¡ ì‹¤íŒ¨ ì‹œ
        """
        send_video_status_update(
            update_url=self.update_url,
            frfr_id=frfr_id,
            analysis_id=analysis_id,
            video_updates=[
                {
                    "video_name": video_name,
                    "analysis_status": analysis_status.to_code()
                }
            ]
        )
        self.logger.info(f"âœ“ Video Status ì—…ë°ì´íŠ¸ ì™„ë£Œ: status={analysis_status.to_code()}")

    def _on_secondary_tasks_start(self, data_item: Dict[str, Any], vid_dir: str, loop_context: Dict[str, Any]) -> int:
        """
        ê° ë°ì´í„° ì•„ì´í…œì— ëŒ€í•´ secondary tasks ì‹¤í–‰ ì§ì „ í˜¸ì¶œë˜ëŠ” ì½œë°±
        
        ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íë¦„:
        1. ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        2. íŒŒì¼ ê²€ì¦
        3. Job Queue ë“±ë¡
        4. Video Status ì „ì†¡
        5. ì—ëŸ¬ ì²˜ë¦¬

        Args:
            data_item: í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë°ì´í„° ì•„ì´í…œ (video_name, video_url í¬í•¨)
            vid_dir: ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            loop_context: Jobì˜ ë£¨í”„ ì»¨í…ìŠ¤íŠ¸ (work_id, frfr_id, analysis_id ë“±)
            
        Raises:
            FileNotFoundError: ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ
            HttpRequestError: ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ì‹œ
        """
        try:

            # 1. ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
            context = self._extract_callback_context(data_item, loop_context)

            # 2. íŒŒì¼ ê²€ì¦ ë° ìƒíƒœ ê²°ì •
            file_exists, analysis_status = self._validate_video_file(context['video_url'])                     

            # 3. Job Queueì— ë“±ë¡
            job_id = self._register_job_to_queue(
                work_id=context['work_id'],
                frfr_id=context['frfr_id'],
                analysis_id=context['analysis_id'],
                video_url=context['video_url'],
                workspace=vid_dir,
                file_exists=file_exists
            )

            # 4. Video Status ì „ì†¡
            self._send_video_status(
                frfr_id=context['frfr_id'],
                analysis_id=context['analysis_id'],
                video_name=context['video_name'],
                analysis_status=analysis_status
            )            

            # 5. íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
            if not file_exists:
                raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {context['video_url']}")

            return job_id

        except HttpRequestError as e:
            self.logger.error(f"âŒ ë°ì´í„° ì—…ë°ì´íŠ¸ ìš”ì²­ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
        except FileNotFoundError:
            raise
        except Exception as e:
            self.logger.error(f"âŒ ì½œë°± ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}", exc_info=True)
            raise
