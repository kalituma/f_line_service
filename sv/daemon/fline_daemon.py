from typing import Dict, Any, Optional
from datetime import datetime

try:
    import ray  # type: ignore
except ImportError:
    ray = None  # type: ignore

from sv import LOG_DIR_PATH
from sv.utils.logger import setup_common_logger, setup_logger

from sv.backend.service.app_state_manager import get_app_state_manager, AppState
from sv.daemon.module.recovery_check import RecoveryCheckService

from sv.daemon.module.job_manager import JobManager
from sv.daemon.module.task_manager import TaskManager
from sv.daemon.module.event_processor import EventProcessor
from sv.daemon.module.execution_engine import ExecutionEngine
from sv.daemon.module.thread_manager import ThreadManager

from sv.backend.f_line_webserver import initialize_web_app

logger = setup_logger(__name__)

def initialize_logger(log_dir_path=None):
    """
    ê³µí†µ ë¡œê±° ì´ˆê¸°í™” (ì‹¤í–‰ ì‹œê°„ì„ íŒŒì¼ëª…ì— í¬í•¨)

    Args:
        log_dir_path: ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: sv.LOG_DIR_PATH)

    Returns:
        Path: ìƒì„±ëœ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    """
    if log_dir_path is None:
        log_dir_path = LOG_DIR_PATH

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir_path / f"f_line_server_{timestamp}.log"
    setup_common_logger(log_file)

    return log_file

class FlineDaemon:
    """
    ì´ë²¤íŠ¸ ê¸°ë°˜ Daemon
    """
    def __init__(
        self,
        base_work_dir: str,
        num_executors: int = 2,
        poll_interval: float = 2.0,
        web_host: str = "localhost",
        web_port: int = 8090,
    ):
        """
        Args:
            num_executors: Ray Actor ê°œìˆ˜
            poll_interval: Event Listener í´ë§ ê°„ê²©
        """

        self.web_app = initialize_web_app(self)
        self.recovery_service = RecoveryCheckService()
        self.app_state = get_app_state_manager()

        # ==================== ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ====================
        self.job_manager = JobManager()
        self.task_manager = TaskManager()

        self.event_processor = EventProcessor(
            poll_interval=poll_interval,
            on_job_created=self._on_job_created
        ) # including listener

        # ExecutionEngine ë¨¼ì € ì´ˆê¸°í™”
        self.execution_engine = ExecutionEngine(base_work_dir, num_executors)
        
        # ThreadManager ì´ˆê¸°í™” ì‹œ ExecutionEngine ì „ë‹¬
        self.thread_manager = ThreadManager(
            poll_interval=poll_interval,
            web_app=self.web_app,
            web_host=web_host,
            web_port=web_port,
            execution_engine=self.execution_engine  # Ray Job Monitorë¥¼ ìœ„í•´ ì „ë‹¬
        )
        
        # Thread Manager ì½œë°± ì„¤ì •
        self.thread_manager.set_check_changes_callback(
            self.event_processor.check_changes
        )
        self.thread_manager.set_process_jobs_callback(
            self._process_pending_jobs
        )
        
        logger.info("=" * 80)
        logger.info("   FlineDaemon initialized")
        logger.info(f"  Executors: {num_executors}")
        logger.info(f"  Poll Interval: {poll_interval}s")
        logger.info("=" * 80)
    
    # ==================== Job Management API ====================
    
    def add_job(self, frfr_id: str, analysis_id: str) -> Optional[int]:
        """
        ìƒˆë¡œìš´ Job ì¶”ê°€
        
        Args:
            frfr_id: ì‚°ë¶ˆ ì •ë³´ ID
            analysis_id: ë¶„ì„ ID
            
        Returns:
            ìƒì„±ëœ job_id
        """
        return self.job_manager.add_job(frfr_id, analysis_id)
    
    def get_job_status(self, job_id: int) -> Optional[Dict[str, Any]]:
        """Job ìƒíƒœ ì¡°íšŒ"""
        return self.job_manager.get_job_status(job_id)
    
    # ==================== Task Management API ====================
    
    def register_primary_task(self, task):
        """Primary Task ë“±ë¡"""
        self.task_manager.register_primary_task(task)
    
    def register_secondary_tasks(self, tasks):
        """Secondary Tasks ë“±ë¡"""
        self.task_manager.register_secondary_tasks(tasks)
    
    def set_data_splitter(self, splitter):
        """ë°ì´í„° ë¶„í•  í•¨ìˆ˜ ë“±ë¡"""
        self.task_manager.set_data_splitter(splitter)
    
    # ==================== Internal Event Handlers ====================
    
    def _on_job_created(self) -> None:
        """Job ìƒì„± ê°ì§€ ì‹œ í•¸ë“¤ëŸ¬ (Event Processorì—ì„œ í˜¸ì¶œ)"""
        logger.info("Job creation event detected")
        self._process_pending_jobs()
    
    def _process_pending_jobs(self) -> None:
        """
        ëŒ€ê¸° ì¤‘ì¸ Job ì²˜ë¦¬ (ë¹„ë™ê¸° ì½œë°± ë°©ì‹)
        
        Flow:
        1. ë‹¤ìŒ PENDING Job ê°€ì ¸ì˜¤ê¸°
        2. Task ì‹¤í–‰ (ë…¼ë¸”ë¡œí‚¹)
        3. ì™„ë£Œ ì‹œ _on_job_complete ì½œë°± í˜¸ì¶œ
        """
        job_info = self.job_manager.get_next_pending_job()
        
        if not job_info:
            logger.debug("No pending jobs")
            return
        
        # Task ì‹¤í–‰ ì¤€ë¹„ í™•ì¸
        if not self.task_manager.are_tasks_ready():
            logger.error("âŒ Tasks not ready for execution")
            return
        
        # Task ì‹¤í–‰ (ë…¼ë¸”ë¡œí‚¹ - ì½œë°± ë°©ì‹)
        self.execution_engine.execute_job(
            job_info=job_info,
            primary_task=self.task_manager.primary_task,
            secondary_tasks=self.task_manager.secondary_tasks,
            data_splitter=self.task_manager.data_splitter,
            on_complete=self._on_job_complete  # ì½œë°± í•¨ìˆ˜
        )
        
        logger.info(f"âœ“ Job {job_info['job_id']} (frfr_id={job_info['frfr_id']}) submitted")
    
    def _on_job_complete(self, job_id: int, result: Dict[str, Any]) -> None:
        """
        Job ì™„ë£Œ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜
        
        Args:
            job_id: ì™„ë£Œëœ Job ID
            result: ì‹¤í–‰ ê²°ê³¼
        """
        logger.info(f"ğŸ“¥ Job {job_id} completed callback received")
        
        # ê²°ê³¼ ë¡œê¹…
        self.execution_engine.log_execution_result(job_id, result)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        status = "completed" if result.get('status') == 'success' else "failed"
        self.job_manager.update_job_status(job_id, status)
        
        logger.info(f"âœ… Job {job_id} status updated to: {status}")

    async def restore_and_init(self) -> bool:
        """
        ë³µêµ¬ ë° ì´ˆê¸°í™” ìˆ˜í–‰ (RecoveryCheckService ì‹¤í–‰)

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        logger.info("=" * 80)
        logger.info("Starting Daemon Initialization...")
        logger.info("=" * 80)

        # RecoveryCheckServiceì˜ ëª¨ë“  ì‘ì—… ì‹¤í–‰
        success = await self.recovery_service.run_all()

        if success:
            await self.app_state.set_state(AppState.READY)
            logger.info("=" * 80)
            logger.info("âœ… Daemon is READY!")
            logger.info("=" * 80)
        else:
            await self.app_state.set_state(AppState.SHUTDOWN)
            logger.error("=" * 80)
            logger.error("âŒ Daemon Initialization FAILED!")
            logger.error("=" * 80)

        return success

    # ==================== Lifecycle Management ====================
    
    def start(self) -> None:
        """Daemon ì‹œì‘"""
        logger.info("Starting FlineDaemon...")
        self.thread_manager.start()
        logger.info("FlineDaemon started successfully")
    
    def stop(self) -> None:
        """Daemon ì¤‘ì§€"""
        logger.info("Stopping FlineDaemon...")
        self.thread_manager.stop()
        logger.info("FlineDaemon stopped")
    
    # ==================== Status API ====================
    
    def get_status(self) -> Dict[str, Any]:
        """Daemon ìƒíƒœ ì¡°íšŒ"""
        return {
            'daemon': {
                'running': self.thread_manager.running
            },
            'tasks': self.task_manager.get_tasks_summary(),
            'threads': self.thread_manager.get_status(),
            'executor': self.execution_engine.get_executor_status()
        }
    
    def get_summary(self) -> str:
        """Daemon ìƒíƒœ ìš”ì•½ (ë¡œê¹…ìš©)"""
        status = self.get_status()
        return (
            f"Running: {status['daemon']['running']} | "
            f"Tasks: {status['tasks']['secondary_tasks_count']} | "
            f"Listener: {status['threads']['listener_active']} | "
            f"RayMonitor: {status['threads']['ray_monitor_active']}"
        )

if __name__ == '__main__':
    # 1. Ray ì´ˆê¸°í™”
    ray.init(num_cpus=8, ignore_reinit_error=True)

    log_file = initialize_logger()
    app_state = get_app_state_manager()

    logger.info("Starting F-line Server with Daemon...")
    logger.info(f"Log file: {log_file}")
    logger.info(f"App state: {app_state.get_state().value}")

    daemon = FlineDaemon()
    # daemon.register_primary_task(DataCollectionTask())
    # daemon.register_secondary_tasks([
    #     ProcessingTask(),
    #     SavingTask()
    # ])
    # daemon.set_data_splitter(split_items)